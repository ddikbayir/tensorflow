This short document describes the steps necessary to reproduce the runtime error when we try to train the Inceptionv3 model with our custom TensorFlow version.
Our custom TF version is only different in core/common_runtime/placer.cc, we simply disable colocation and the standard placer algorithm and enforce a custom placement.
The custom version is located at custom-1.14.0 branch of this repo.

Prerequisites:
- CUDA 10.0, CUDNN 7.4, Bazel 0.24.1
- A machine with at least two GPU devices

Download and set up Inception repo (https://github.com/tensorflow/models/tree/master/research/inception):

Prepare training data:
	# location of where to place the training data
	DATA_DIR=$HOME/path/to/training/data

	# build the preprocessing script.
	cd path/to/inception-repo
	bazel build //inception:download_and_preprocess_flowers

	# run it
	bazel-bin/inception/download_and_preprocess_flowers "${DATA_DIR}"
Train model:
	bazel build //inception:flowers_train

	bazel-bin/inception/flowers_train --growth=True --num_gpus=1 --batch_size=32 --log_device_placement=True --max_steps=100 --data_dir=/path/to/flowers_data

Steps to reproduce the error:

1-) Get the custom TF repository and switch to branch "custom-1.14.0" (https://github.com/ddikbayir/tensorflow)

2-) Run ./configure script (XLA disabled,CUDA enabled) and then build TF from source using bazel 
    Note-1: the pre-build configuration of TF is interactive, therefore I couldn't automate the building phase. After running ./configure under TF repo root, simply run:
        - bazel build //tensorflow/tools/pip_package:build_pip_package
        - bazel-bin/tensorflow/tools/pip_package/build_pip_package /path/to/whl/out-folder
        - pip install /path/to/whl_file (uninstall other versions of TF)
    Note-2: When I configure with no XLA option, the ./configure script still enables it for me. To prevent this, change "build:xla --define with_xla_support=true" in .tf_configure.bazelrc to "false".
3-) Make sure the $HOME env variable is set and put "placement.place" under your $HOME folder
4-) When using the command to train the Inception model, the runtime error appears.
